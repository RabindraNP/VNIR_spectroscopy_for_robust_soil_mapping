<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 4 Sampling | R code for Robust soil mapping at the farm scale with vis-NIR spectroscopy (Ramirez-Lopez et al., 2019)</title>
  <meta name="description" content="Here you will find all the code necessary to reproduce the methods we used in our paper ‘Robust soil mapping at the farm scale with vis-NIR spectroscopy’" />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 4 Sampling | R code for Robust soil mapping at the farm scale with vis-NIR spectroscopy (Ramirez-Lopez et al., 2019)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Here you will find all the code necessary to reproduce the methods we used in our paper ‘Robust soil mapping at the farm scale with vis-NIR spectroscopy’" />
  <meta name="github-repo" content="l-ramirez-lopez/VNIR_spectroscopy_for_robust_soil_mapping" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 4 Sampling | R code for Robust soil mapping at the farm scale with vis-NIR spectroscopy (Ramirez-Lopez et al., 2019)" />
  
  <meta name="twitter:description" content="Here you will find all the code necessary to reproduce the methods we used in our paper ‘Robust soil mapping at the farm scale with vis-NIR spectroscopy’" />
  

<meta name="author" content="Leo Ramirez-Lopez (BUCHI Labortechnik AG, Switzerland)" />
<meta name="author" content="Alex Wadoux (Wageningen University, Netherlands)" />


<meta name="date" content="2019-06-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="required-data.html">
<link rel="next" href="splitting-the-data.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.2/leaflet.js"></script>
<script src="libs/leaflet-providers-1.1.17/leaflet-providers.js"></script>
<script src="libs/leaflet-providers-plugin-2.0.2/leaflet-providers-plugin.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Soil mapping with VNIR</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#paper-summary"><i class="fa fa-check"></i><b>1.1</b> Paper summary</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#study-area"><i class="fa fa-check"></i><b>1.2</b> Study area</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#in-case-of-commentsquestionsissues"><i class="fa fa-check"></i><b>1.3</b> In case of comments/questions/issues</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#for-citation-or-details-please-refer-to"><i class="fa fa-check"></i><b>1.4</b> For citation or details please refer to:</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#notes"><i class="fa fa-check"></i><b>1.5</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="required-r-packages.html"><a href="required-r-packages.html"><i class="fa fa-check"></i><b>2</b> Required <code>R</code> packages</a></li>
<li class="chapter" data-level="3" data-path="required-data.html"><a href="required-data.html"><i class="fa fa-check"></i><b>3</b> Required data</a></li>
<li class="chapter" data-level="4" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>4</b> Sampling</a><ul>
<li class="chapter" data-level="4.1" data-path="sampling.html"><a href="sampling.html#optimal-calibration-set-size-identification"><i class="fa fa-check"></i><b>4.1</b> Optimal calibration set size identification</a></li>
<li class="chapter" data-level="4.2" data-path="sampling.html"><a href="sampling.html#plotting-the-results"><i class="fa fa-check"></i><b>4.2</b> Plotting the results</a></li>
<li class="chapter" data-level="4.3" data-path="sampling.html"><a href="sampling.html#final-selection-of-the-calibration-set"><i class="fa fa-check"></i><b>4.3</b> Final selection of the calibration set</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="splitting-the-data.html"><a href="splitting-the-data.html"><i class="fa fa-check"></i><b>5</b> Splitting the data</a></li>
<li class="chapter" data-level="6" data-path="transformation-of-the-particle-size-data.html"><a href="transformation-of-the-particle-size-data.html"><i class="fa fa-check"></i><b>6</b> Transformation of the particle-size data</a></li>
<li class="chapter" data-level="7" data-path="visnir-modelling-and-predictions.html"><a href="visnir-modelling-and-predictions.html"><i class="fa fa-check"></i><b>7</b> Vis–NIR modelling and predictions</a><ul>
<li class="chapter" data-level="7.1" data-path="visnir-modelling-and-predictions.html"><a href="visnir-modelling-and-predictions.html#calibration-and-validation"><i class="fa fa-check"></i><b>7.1</b> Calibration and validation</a></li>
<li class="chapter" data-level="7.2" data-path="visnir-modelling-and-predictions.html"><a href="visnir-modelling-and-predictions.html#property-predictions-in-the-prediction-set"><i class="fa fa-check"></i><b>7.2</b> Property predictions in the prediction set</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="prepare-the-vis-nir-augmented-dataset.html"><a href="prepare-the-vis-nir-augmented-dataset.html"><i class="fa fa-check"></i><b>8</b> Prepare the vis-NIR augmented dataset</a></li>
<li class="chapter" data-level="9" data-path="spatial-modeling.html"><a href="spatial-modeling.html"><i class="fa fa-check"></i><b>9</b> Spatial modeling</a><ul>
<li class="chapter" data-level="9.1" data-path="spatial-modeling.html"><a href="spatial-modeling.html#robust-fitting-of-the-spatial-models"><i class="fa fa-check"></i><b>9.1</b> Robust fitting of the spatial models</a><ul>
<li class="chapter" data-level="9.1.1" data-path="spatial-modeling.html"><a href="spatial-modeling.html#laboratory-based-data"><i class="fa fa-check"></i><b>9.1.1</b> Laboratory-based data</a></li>
<li class="chapter" data-level="9.1.2" data-path="spatial-modeling.html"><a href="spatial-modeling.html#augmented-vis-nir-data"><i class="fa fa-check"></i><b>9.1.2</b> Augmented vis-NIR data</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="spatial-modeling.html"><a href="spatial-modeling.html#accounting-for-vis-nir-model-errors-in-the-spatial-models"><i class="fa fa-check"></i><b>9.2</b> Accounting for vis-NIR model errors in the spatial models</a></li>
<li class="chapter" data-level="9.3" data-path="spatial-modeling.html"><a href="spatial-modeling.html#validation-of-the-spatial-models"><i class="fa fa-check"></i><b>9.3</b> Validation of the spatial models</a><ul>
<li class="chapter" data-level="9.3.1" data-path="spatial-modeling.html"><a href="spatial-modeling.html#laboratory-based-data-1"><i class="fa fa-check"></i><b>9.3.1</b> Laboratory-based data</a></li>
<li class="chapter" data-level="9.3.2" data-path="spatial-modeling.html"><a href="spatial-modeling.html#vis-nir-augmented-based-data"><i class="fa fa-check"></i><b>9.3.2</b> Vis-NIR augmented-based data</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="spatial-modeling.html"><a href="spatial-modeling.html#mapping"><i class="fa fa-check"></i><b>9.4</b> Mapping</a><ul>
<li class="chapter" data-level="9.4.1" data-path="spatial-modeling.html"><a href="spatial-modeling.html#laboratory-based-data-2"><i class="fa fa-check"></i><b>9.4.1</b> Laboratory-based data</a></li>
<li class="chapter" data-level="9.4.2" data-path="spatial-modeling.html"><a href="spatial-modeling.html#vis-nir-augmented-based-data-1"><i class="fa fa-check"></i><b>9.4.2</b> Vis-NIR augmented-based data</a></li>
<li class="chapter" data-level="9.4.3" data-path="spatial-modeling.html"><a href="spatial-modeling.html#plots"><i class="fa fa-check"></i><b>9.4.3</b> Plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://onlinelibrary.wiley.com/doi/10.1111/ejss.12752" target="blank">End</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R code for Robust soil mapping at the farm scale with vis-NIR spectroscopy (Ramirez-Lopez <em>et al.</em>, 2019)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sampling" class="section level1">
<h1><span class="header-section-number">Section 4</span> Sampling</h1>
<hr />
<div id="optimal-calibration-set-size-identification" class="section level2">
<h2><span class="header-section-number">4.1</span> Optimal calibration set size identification</h2>
<p>In this section we show how the optimal size for a calibration set is identified using the mean squared
Euclidean distance (<span class="math inline">\(msd\)</span>) between estimates of the probability density functions (<span class="math inline">\(pdfs\)</span>) of the whole set of samples and the pdfs of subsets with different sizes.<br />
First we compute the principal components (PCs) of the NIR spectra of the whole set of calibration candidate samples. Then for each component we compute kernel density estimates (<span class="math inline">\(KDE\)</span>):</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## Apply standard normal variate </span>
data<span class="op">$</span>spc_snv &lt;-<span class="st"> </span><span class="kw">standardNormalVariate</span>(data<span class="op">$</span>spc)

<span class="co">## extract the validation samples into a new set/object</span>
valida &lt;-<span class="st"> </span>data[data<span class="op">$</span>set <span class="op">==</span><span class="st"> &quot;validation&quot;</span>,]

<span class="co">## remove the validation samples from data</span>
data &lt;-<span class="st"> </span>data[data<span class="op">$</span>set <span class="op">==</span><span class="st"> &quot;cal_candidate&quot;</span>,]

<span class="co">## --- 2. Perform a principal component analysis  ----</span>
<span class="co">## Compress the data </span>
pcaall &lt;-<span class="st"> </span><span class="kw">orthoProjection</span>(<span class="dt">Xr =</span> data<span class="op">$</span>spc_snv, 
                          <span class="dt">X2 =</span> <span class="ot">NULL</span>, 
                          <span class="dt">Yr =</span> <span class="ot">NULL</span>, 
                          <span class="dt">method =</span> <span class="st">&quot;pca&quot;</span>, 
                          <span class="dt">pcSelection =</span> <span class="kw">list</span>(<span class="st">&quot;cumvar&quot;</span>, <span class="fl">0.99</span>), 
                          <span class="dt">center =</span> <span class="ot">TRUE</span>, 
                          <span class="dt">scaled =</span> <span class="ot">FALSE</span>)
                          
<span class="co">## standardize the socres</span>
pcaall<span class="op">$</span>scores.std &lt;-<span class="st"> </span><span class="kw">sweep</span>(pcaall<span class="op">$</span>scores, <span class="dt">MARGIN =</span> <span class="dv">2</span>, <span class="dt">STATS =</span> pcaall<span class="op">$</span>sc.sdv, <span class="dt">FUN =</span> <span class="st">&quot;/&quot;</span>)

<span class="co">## compute the max and min of each score for the limits of the density estimations</span>
max.sc &lt;-<span class="st"> </span><span class="kw">colMins</span>(pcaall<span class="op">$</span>scores.std)
min.sc &lt;-<span class="st"> </span><span class="kw">colMaxs</span>(pcaall<span class="op">$</span>scores.std)

<span class="co">## compute the mean and sd of each score for the comparisons with the samples</span>
mean.sc &lt;-<span class="st"> </span><span class="kw">colMeans</span>(pcaall<span class="op">$</span>scores.std)
sd.sc &lt;-<span class="st"> </span><span class="kw">colSds</span>(pcaall<span class="op">$</span>scores.std)

<span class="co"># number of points in the density distribution</span>
nxdens &lt;-<span class="st"> </span><span class="dv">500</span>

<span class="co">## matrix where the density values will be stored</span>
ix &lt;-<span class="st"> </span><span class="dv">1</span>
sc.dens &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">seq</span>(min.sc[ix], max.sc[ix], <span class="dt">length =</span> nxdens), 
                      <span class="kw">matrix</span>(<span class="ot">NA</span>, nxdens, <span class="kw">length</span>(min.sc)))
<span class="kw">colnames</span>(sc.dens) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;x&quot;</span>, <span class="kw">paste</span>(<span class="st">&quot;densc&quot;</span>, <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(min.sc), <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))

<span class="co">## Kernel density estimates (KDE) of each component </span>
d.bandwidths &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">length</span>(min.sc))
<span class="kw">names</span>(d.bandwidths) &lt;-<span class="st"> </span><span class="kw">colnames</span>(pcaall<span class="op">$</span>scores.std)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(min.sc)){
  idsty &lt;-<span class="st"> </span><span class="kw">density</span>(pcaall<span class="op">$</span>scores.std[,i], 
                   <span class="dt">bw =</span> <span class="st">&quot;nrd0&quot;</span>, 
                   <span class="dt">n =</span> nxdens, <span class="dt">from =</span> min.sc[i], <span class="dt">to =</span> max.sc[i], 
                   <span class="dt">kernel =</span> <span class="st">&quot;gaussian&quot;</span>)
  sc.dens[,i<span class="op">+</span><span class="dv">1</span>] &lt;-<span class="st"> </span>idsty<span class="op">$</span>y
  d.bandwidths[i] &lt;-<span class="st"> </span>idsty<span class="op">$</span>bw
}

<span class="co">## Create the vector of different sample set sizes to be tested</span>
css &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">10</span>, <span class="dv">400</span>, <span class="dt">by =</span> <span class="dv">10</span>)</code></pre>
<p>Now we will iterate over the different calibration set sizes (<code>css</code>). We are going to use the LHS algorithm to select subsets from our set of candiate samples for calibartion. This is done using the (standardized) scores of the principal components (PCs) of the spectra (<code>pcaall$scores.std</code>). For each calibration subset we’ll compute the mean squared Euclidean distance (<span class="math inline">\(msd\)</span>) between estimates of the probability density functions (<span class="math inline">\(pdfs\)</span>) of the whole set of samples and the <span class="math inline">\(pdfs\)</span> of samples in the subset. The <span class="math inline">\(msd\)</span> is computed using kernel density estimates (<span class="math inline">\(KDE\)</span>) of the <span class="math inline">\(pdfs\)</span>. To obtain reliable estimates of <span class="math inline">\(msd\)</span> as a function of the sample set size, we will repeat 10 times (<code>repetitions</code>) the whole sampling procedure for each <code>css</code>, the final <span class="math inline">\(msd\)</span> will be the the average of the <span class="math inline">\(msd\)</span>s obtained at each iteration.
The following pseudo-code summarizes the procedure to compute the <span class="math inline">\(msd\)</span> (see the ‘<em>Calibration samples</em>’ section in our paper for more details):</p>
<pre class="text"><code>Input:  PCs of the whole set of candidate samples (p);
        KDEs of the PCs of the whole set of candidate samples;
Output: msd

1 for each repetition do:
2   for each proposed sampling size do:
3     select from the PCs a subset (s);
4     for each component in s and p:
5       compute the msd between KDE(s,component) and KDE(p,component);
6     end
7   end
8 end

9 aggregate the results of the msds obatined for all 
the repetition iterations for each sample set size</code></pre>
<p>First we’ll compute the <span class="math inline">\(msd\)</span>s for ecah repetition and we will write each set of results into our working directory.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## Sample with LHS (latin hypercube sampling)</span>

<span class="co">## These three nested loops might take a while</span>
<span class="co">## (aprox. 16 min per repetition, i.e. a bit more than a couple of hours </span>
<span class="co">## for the whole thing)</span>
<span class="co">## (for reducing the computation time the loops</span>
<span class="co">## can be vectorized using the apply family of functions. </span>
<span class="co">## Furtheromre parallelization of the loop for the repetitions</span>
<span class="co">## can also be applied)</span>
<span class="co">## We present the computations with nested loops for interpretability </span>
<span class="co">## reasons</span>

repetitions &lt;-<span class="st"> </span><span class="dv">10</span>

<span class="co">## root name for the results of each iteration</span>
filerootname &lt;-<span class="st"> &quot;6pcs_resultsclhs_rep&quot;</span>

<span class="co">## Create the data.frame where the results will be stored </span>
<span class="co">## at each iteration</span>
results.clhs &lt;-<span class="st">  </span><span class="kw">data.frame</span>(<span class="dt">css =</span> css, 
                            <span class="dt">msd =</span> <span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">length</span>(css)),
                            <span class="dt">mndiff =</span> <span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">length</span>(css)),
                            <span class="dt">sddiff =</span> <span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">length</span>(css)))
<span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>repetitions){
  results.clhs[,<span class="op">-</span><span class="dv">1</span>] &lt;-<span class="st"> </span><span class="ot">NA</span>
  
  <span class="co">## Define a file name</span>
  fn &lt;-<span class="st"> </span><span class="kw">paste</span>(filerootname, k,<span class="st">&quot;.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
  <span class="cf">if</span>(fn <span class="op">%in%</span><span class="st"> </span><span class="kw">list.files</span>()){
    results.clhs &lt;-<span class="st"> </span><span class="kw">read.table</span>(fn, <span class="dt">header =</span> T, <span class="dt">sep =</span> <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>)
  }
  
  iter.p &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">rowSums</span>(<span class="op">!</span><span class="kw">is.na</span>(results.clhs)) <span class="op">==</span><span class="st"> </span><span class="kw">ncol</span>(results.clhs))
  
  <span class="cf">for</span>(i <span class="cf">in</span> iter.p<span class="op">:</span><span class="kw">length</span>(css)){
    <span class="kw">set.seed</span>(k)
    i.calidx &lt;-<span class="st"> </span><span class="kw">clhs</span>(<span class="dt">x =</span> <span class="kw">as.data.frame</span>(pcaall<span class="op">$</span>scores.std),
                     <span class="dt">size =</span> css[i], 
                     <span class="dt">iter =</span> <span class="dv">10000</span>)
    
    <span class="co">## Compute the KDEs of each PC</span>
    j.sc.dens &lt;-<span class="st"> </span>msd.sc  &lt;-<span class="st"> </span>sc.dens 
    <span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(min.sc)){
      <span class="co">## use the same bandwidth (bw) as in the whole set of candidates</span>
      j.sc.dens[,j <span class="op">+</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">density</span>(<span class="dt">x =</span> pcaall<span class="op">$</span>scores.std[i.calidx,j], 
                                   <span class="dt">bw =</span> d.bandwidths[j], 
                                   <span class="dt">n =</span> nxdens, 
                                   <span class="dt">from =</span> min.sc[j], 
                                   <span class="dt">to =</span> max.sc[j], 
                                   <span class="dt">kernel =</span> <span class="st">&quot;gaussian&quot;</span>)<span class="op">$</span>y
    }
    results.clhs<span class="op">$</span>msd[i] &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">colMeans</span>((j.sc.dens[,<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>sc.dens[,<span class="op">-</span><span class="dv">1</span>])<span class="op">^</span><span class="dv">2</span>, <span class="dt">na.rm =</span> T))
    results.clhs<span class="op">$</span>mndiff[i] &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">abs</span>(<span class="kw">colMeans</span>(pcaall<span class="op">$</span>scores.std[i.calidx,])))
    results.clhs<span class="op">$</span>sddiff[i] &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">abs</span>(<span class="kw">colSds</span>(pcaall<span class="op">$</span>scores.std[i.calidx,]) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))
    
    <span class="co">## write the results obtained so far...</span>
    <span class="cf">if</span>(iter <span class="op">==</span><span class="st"> </span><span class="kw">length</span>(nmsrepsclhs)){
      final.clhs &lt;-<span class="st"> </span>final.clhs<span class="op">/</span>iter
      <span class="kw">write.table</span>(<span class="dt">x =</span> final.clhs, 
                  <span class="dt">file =</span> <span class="st">&quot;6pcs_final.clhs.txt&quot;</span>, 
                  <span class="dt">sep =</span> <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>, 
                  <span class="dt">row.names =</span> <span class="ot">FALSE</span>)
    }
    
    <span class="kw">print</span>(results.clhs[<span class="dv">1</span><span class="op">:</span>i,])
  }
}</code></pre>
<p>After executing the above nested loops, you should have obtained 10 different *.txt files in your working directorty (in this case the root name of the files is 6pcs_resultsclhs_rep[n].txt where [n] represents the repetition number). These files contain the <span class="math inline">\(msd\)</span> results obtained at each repetition iteration.
Now we’ll calculate the final <span class="math inline">\(msd\)</span> as the average of the ones obtained at each repetition iteration.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## Specify a file name for the file where the final results will be stored</span>
finalresultsfile &lt;-<span class="st"> &quot;6pcs_final.clhs.txt&quot;</span>

nmsrepsclhs &lt;-<span class="st"> </span><span class="kw">paste</span>(filerootname, <span class="dv">1</span><span class="op">:</span>repetitions, <span class="st">&quot;.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
final.clhs &lt;-<span class="st"> </span><span class="dv">0</span>
<span class="cf">for</span>(i <span class="cf">in</span> nmsrepsclhs){
  iter &lt;-<span class="st"> </span><span class="kw">which</span>(i <span class="op">==</span><span class="st"> </span>nmsrepsclhs)
  results.clhs &lt;-<span class="st"> </span><span class="kw">read.table</span>(i, <span class="dt">header =</span> T, <span class="dt">sep =</span> <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>)
  results.clhs<span class="op">$</span>mndiff &lt;-<span class="st"> </span><span class="kw">abs</span>(results.clhs<span class="op">$</span>mndiff)
  final.clhs &lt;-<span class="st"> </span>final.clhs <span class="op">+</span><span class="st"> </span>results.clhs

  <span class="co">## write a table with the final results </span>
  <span class="cf">if</span>(iter <span class="op">==</span><span class="st"> </span><span class="kw">length</span>(nmsrepsclhs)){
    final.clhs &lt;-<span class="st"> </span>final.clhs<span class="op">/</span>iter
    <span class="kw">write.table</span>(<span class="dt">x =</span> final.clhs, 
                <span class="dt">file =</span> finalresultsfile, 
                <span class="dt">sep =</span> <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>, 
                <span class="dt">row.names =</span> <span class="ot">FALSE</span>)
  }
}

<span class="co">## Compute the standard devitions of the msd results</span>
final.clhs_sd &lt;-<span class="st"> </span><span class="dv">0</span>
<span class="cf">for</span>(i <span class="cf">in</span> nmsrepsclhs){
  iter &lt;-<span class="st"> </span><span class="kw">which</span>(i <span class="op">==</span><span class="st"> </span>nmsrepsclhs)
  results.clhs &lt;-<span class="st"> </span><span class="kw">read.table</span>(i, <span class="dt">header =</span> T, <span class="dt">sep =</span> <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>)
  results.clhs<span class="op">$</span>mndiff &lt;-<span class="st"> </span><span class="kw">abs</span>(results.clhs<span class="op">$</span>mndiff)
  final.clhs_sd &lt;-<span class="st"> </span>(results.clhs <span class="op">-</span><span class="st"> </span>final.clhs_sd)<span class="op">^</span><span class="dv">2</span>
  <span class="cf">if</span>(iter <span class="op">==</span><span class="st"> </span><span class="kw">length</span>(nmsrepsclhs)){
    final.clhs_sd &lt;-<span class="st"> </span>(final.clhs_sd<span class="op">/</span>iter)<span class="op">^</span><span class="fl">0.5</span>
  }
}</code></pre>
<p>After executing the above code, a file with the final <span class="math inline">\(msd\)</span> estimations is writen in your working directory. In addition the standard deviations of the <span class="math inline">\(msd\)</span> for the different set sizes was also computed and stored in the object <code>final.clhs_sd</code>.</p>
</div>
<div id="plotting-the-results" class="section level2">
<h2><span class="header-section-number">4.2</span> Plotting the results</h2>
<p>To plot the <span class="math inline">\(msd\)</span> results using <code>ggplot</code> (Figure 3 in our paper):</p>
<pre class="sourceCode r"><code class="sourceCode r">final.clhs_plot &lt;-<span class="st"> </span><span class="kw">data.frame</span>(final.clhs[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>], 
                              <span class="dt">sd_lower =</span> final.clhs[,<span class="dv">2</span>] <span class="op">-</span><span class="st"> </span>final.clhs_sd[,<span class="dv">2</span>],
                              <span class="dt">sd_upper =</span> final.clhs[,<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>final.clhs_sd[,<span class="dv">2</span>])

p.tmp &lt;-<span class="st"> </span><span class="kw">ggplot</span>(final.clhs_plot) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> css, msd, <span class="dt">colour =</span> <span class="st">&quot;msd&quot;</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.y =</span> <span class="kw">element_text</span>(<span class="dt">face=</span> <span class="st">&quot;bold.italic&quot;</span>, <span class="dt">colour =</span> <span class="kw">grey</span>(<span class="fl">0.2</span>), <span class="dt">size=</span><span class="dv">18</span>),
        <span class="dt">axis.text.y  =</span> <span class="kw">element_text</span>(<span class="dt">angle=</span><span class="dv">0</span>, <span class="dt">vjust =</span><span class="fl">0.5</span>, <span class="dt">hjust =</span><span class="fl">0.5</span>, <span class="dt">size=</span><span class="dv">14</span>), 
        <span class="dt">legend.title =</span> <span class="kw">element_text</span>(<span class="dt">colour =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">size=</span><span class="dv">20</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_text</span>(<span class="dt">face=</span> <span class="st">&quot;bold&quot;</span>, <span class="dt">colour =</span> <span class="kw">grey</span>(<span class="fl">0.2</span>), <span class="dt">size=</span><span class="dv">18</span>),
        <span class="dt">axis.text.x  =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">0</span>, <span class="dt">vjust=</span><span class="dv">0</span>, <span class="dt">size=</span><span class="dv">14</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.text =</span> <span class="kw">element_text</span>(<span class="dt">face=</span><span class="st">&quot;bold&quot;</span>, <span class="dt">colour =</span> <span class="kw">grey</span>(<span class="fl">0.2</span>), <span class="dt">size=</span><span class="dv">18</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;msd&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;Calibration set size&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="co">#coord_cartesian(ylim = c(0, 8)) + </span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">strip.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;grey&quot;</span>), 
        <span class="dt">strip.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">16</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">angle =</span> <span class="dv">0</span>)) 
        
p.tmp <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>sd_lower, <span class="dt">ymax=</span>sd_upper, <span class="dt">x=</span>css, <span class="dt">colour =</span> <span class="st">&quot;bands&quot;</span>), <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_colour_manual</span>(<span class="dt">name =</span> <span class="st">&#39;&#39;</span>, <span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;bands&quot;</span> =<span class="st"> </span><span class="ot">NA</span>, <span class="st">&quot;msd&quot;</span> =<span class="st"> &quot;black&quot;</span>))</code></pre>
</div>
<div id="final-selection-of-the-calibration-set" class="section level2">
<h2><span class="header-section-number">4.3</span> Final selection of the calibration set</h2>
<p>The previous analysis allows to infer an optimal calibration set size. This optimal size is indicated by the point at which no substantial reduction of the <span class="math inline">\(msd\)</span> is observed. In our case this assestment was intuetively done by looking at the <span class="math inline">\(msd\)</span> vs. <span class="math inline">\(css\)</span> plot. We set the optimal calibration set size (<code>ocss</code>) 180 samples:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Optimal calibration sample set size</span>
ocss &lt;-<span class="st"> </span><span class="dv">180</span></code></pre>
<p>Once the optimal calibration set size is identified, we can propose/sample different calibration sets (solutions) containing 180 samples. In our paper we proposed 10 different solutions and we selected the one that returned the mimimum <span class="math inline">\(msd\)</span> (this subset will be then used as the final calibration set in later analyses):</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## Compute the maximum and minimum of each score for the limits of the</span>
<span class="co">## density estimations</span>
max.sc &lt;-<span class="st"> </span><span class="kw">colMins</span>(pcaall<span class="op">$</span>scores.std)
min.sc &lt;-<span class="st"> </span><span class="kw">colMaxs</span>(pcaall<span class="op">$</span>scores.std)

<span class="co">## Compute the mean and standard deviation of each score for the comparisons</span>
<span class="co">## with the samples</span>
mean.sc &lt;-<span class="st"> </span><span class="kw">colMeans</span>(pcaall<span class="op">$</span>scores.std)
sd.sc &lt;-<span class="st"> </span><span class="kw">colSds</span>(pcaall<span class="op">$</span>scores.std)

<span class="co">## Set a number of solutions to test</span>
solutions &lt;-<span class="st"> </span><span class="dv">10</span>

<span class="co">## object where the sample indices of the different solutions will be stored</span>
calidx &lt;-<span class="st"> </span><span class="ot">NULL</span>

<span class="co">## object where the msds will be stored</span>
results.clhs.ocss &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="dt">length =</span> solutions)

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>solutions) {
                    <span class="co">## set seed for the random number generation</span>
                    <span class="kw">set.seed</span>(<span class="kw">round</span>(i <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="dv">4</span>)))
                    
                    <span class="co">## sample the ith solution</span>
                    i.calidx &lt;-<span class="st"> </span><span class="kw">clhs</span>(<span class="dt">x =</span> <span class="kw">as.data.frame</span>(pcaall<span class="op">$</span>scores.std), <span class="dt">size =</span> ocss, <span class="dt">iter =</span> <span class="dv">10000</span>)
                    
                    <span class="co">## store the indices of the selected samples</span>
                    calidx[[i]] &lt;-<span class="st"> </span>i.calidx
                    
                    <span class="co">## Compute the KDEs</span>
                    j.sc.dens &lt;-<span class="st"> </span>msd.sc &lt;-<span class="st"> </span>sc.dens
                    <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(min.sc)) {
                                        j.sc.dens[, j <span class="op">+</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">density</span>(<span class="dt">x =</span> pcaall<span class="op">$</span>scores.std[i.calidx, j], <span class="dt">bw =</span> d.bandwidths[j], 
                                                            <span class="dt">n =</span> nxdens, <span class="dt">from =</span> min.sc[j], <span class="dt">to =</span> max.sc[j], <span class="dt">kernel =</span> <span class="st">&quot;gaussian&quot;</span>)<span class="op">$</span>y
                    }
                    <span class="co">## compute the msds</span>
                    results.clhs.ocss[i] &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">colMeans</span>((j.sc.dens[, <span class="dv">-1</span>] <span class="op">-</span><span class="st"> </span>sc.dens[, <span class="dv">-1</span>])<span class="op">^</span><span class="dv">2</span>, 
                                        <span class="dt">na.rm =</span> T))
}

<span class="co">## Identify the index of the best group</span>
<span class="kw">plot</span>(results.clhs.ocss)

<span class="co">## best solution</span>
<span class="kw">which.min</span>(results.clhs.ocss)

<span class="co">## get the indices of the samples in the final solution</span>
calibration.idx &lt;-<span class="st"> </span>calidx[[<span class="kw">which.min</span>(results.clhs.ocss)]]

<span class="co">## get the IDs of the samples in the final solution</span>
cal_smpls &lt;-<span class="st"> </span><span class="kw">as.character</span>(data<span class="op">$</span>ID[calibration.idx])</code></pre>
<p>Save the IDs of the selected calibration samples into your working directory</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">writeLines</span>(<span class="dt">text =</span> cal_smpls, <span class="dt">con =</span> <span class="st">&quot;calibration_samples_ids.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="required-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="splitting-the-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "night",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"download": ["soilmappingwithvnir.pdf", "soilmappingwithvnir.epub"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
